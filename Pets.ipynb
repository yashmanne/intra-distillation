{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF4b_vzbWjcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c6f095-9d82-45cc-d802-f24e9ceb0724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "device = torch.device('cuda') #cuda"
      ],
      "metadata": {
        "id": "57JoSpGRyXnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 3\n",
        "p = 5\n",
        "q = 10\n",
        "alpha = 1.5\n",
        "N = 4000\n",
        "num_classes = 37\n",
        "batch_size = 4\n",
        "iter_batch = 15\n",
        "mask_type = 'full'"
      ],
      "metadata": {
        "id": "n4sbu1ukWoKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V1\n",
        "T = weights.transforms()\n",
        "data = torchvision.datasets.OxfordIIITPet('OxfordIIITPet', transform=T, download=True)\n",
        "train, val = torch.utils.data.random_split(data, [3000, 680], generator=torch.Generator().manual_seed(42))\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)\n",
        "test = torchvision.datasets.OxfordIIITPet('OxfordIIITPet', transform=T, download=True, split='test')\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n",
        "model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
        "model.fc = torch.nn.Linear(2048, num_classes, bias=False)"
      ],
      "metadata": {
        "id": "Zm8pGF_-WoM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mixup(x, y, alpha=0.2):\n",
        "    h = torch.distributions.beta.Beta(alpha, 1).rsample((batch_size,))\n",
        "    index = torch.randperm(batch_size)\n",
        "    mixed_x = h[:,None,None,None] * x + (1 - h[:,None,None,None]) * x[index, ...]\n",
        "    mixed_y = h*torch.nn.functional.one_hot(y, num_classes=num_classes) + (1-h) * torch.nn.functional.one_hot(y[index], num_classes=num_classes)\n",
        "    return mixed_x, mixed_y"
      ],
      "metadata": {
        "id": "4u6O0Ib_9Lj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropout(p):\n",
        "    return nn.Sequential(nn.ReLU(), nn.Dropout(p=p))\n",
        "def set_dropout(model, p):\n",
        "    for name, child in model.named_children():\n",
        "        if isinstance(child, nn.ReLU):\n",
        "            model.relu = dropout(p)\n",
        "        set_dropout(child, p)\n",
        "set_dropout(model, 0.1)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "T2BBcrGlO8zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def X_loss(distributions, target_mask):\n",
        "    dict_size = distributions.shape[-1]\n",
        "\n",
        "    m = torch.sum(distributions, dim=0) / distributions.shape[0]\n",
        "    m = m.float().view(-1, dict_size)[target_mask]\n",
        "\n",
        "    kl_all = 0\n",
        "    for l in distributions:\n",
        "        l = l.float().view(-1, dict_size)[target_mask]\n",
        "        d = (l-m) * (torch.log(l) - torch.log(m))\n",
        "        kl_all += d.sum()\n",
        "    return kl_all / distributions.shape[0]\n",
        "\n",
        "def _get_alpha(alpha, num_update, max_update, p, q):\n",
        "    if num_update >= max_update / p or alpha <= 1:\n",
        "        return alpha\n",
        "    else:\n",
        "        alpha = torch.tensor([alpha])\n",
        "        gamma = torch.log(1/alpha) / torch.log(torch.tensor([p/q])) # log_(p/q)(1/alpha)\n",
        "        new_alpha = ( p**gamma * alpha * num_update ** gamma) / (max_update ** gamma)\n",
        "        return new_alpha.item()\n",
        "\n",
        "def build_loss_function(N, p, q, alpha, label_smoothing=0.1, mask_type='full'):\n",
        "    cross_entropy = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "    def loss_function(outputs, true, num_update):\n",
        "        K = outputs.shape[0]\n",
        "        num_classes = outputs.shape[-1]\n",
        "        if mask_type == 'one_hot':\n",
        "            mask = true > 0\n",
        "        elif mask_type == 'full':\n",
        "            mask = torch.ones((batch_size, num_classes)).type(torch.bool)\n",
        "        elif mask_type == 'none':\n",
        "            mask = torch.zeros(num_classes).type(torch.bool)\n",
        "\n",
        "        probabilities = torch.softmax(outputs, -1)\n",
        "        intra_loss = X_loss(probabilities, mask)\n",
        "        expanded_true = true.repeat(K)\n",
        "        expanded_outputs = outputs.reshape(-1, num_classes)\n",
        "        likelihood_loss = cross_entropy(expanded_outputs, expanded_true)\n",
        "        adaptive_alpha = _get_alpha(alpha, num_update, N, p, q)\n",
        "        return likelihood_loss + adaptive_alpha * intra_loss, likelihood_loss, intra_loss\n",
        "    return loss_function"
      ],
      "metadata": {
        "id": "5mmsrebjWoUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_lr = 0.00002\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=0.001)\n",
        "loss_fn = build_loss_function(N, p, q, alpha, mask_type=mask_type)\n",
        "val_loss_fn = torch.nn.CrossEntropyLoss()\n",
        "num_update = 1\n",
        "curve = []\n",
        "optimizer.zero_grad()\n",
        "\n",
        "for epoch in range(80):\n",
        "    train_likelihood = 0\n",
        "    train_intra = 0\n",
        "    val_likelihood = 0\n",
        "\n",
        "    model.train()\n",
        "    for j, (batch, label) in enumerate(train_loader):\n",
        "        outputs = torch.empty(K, batch_size, num_classes)\n",
        "        batch = batch.to(device)\n",
        "        label = label.to(device)\n",
        "        outputs = outputs.to(device)\n",
        "        for i in range(K):\n",
        "            outputs[i] = model(batch)\n",
        "        loss, likelihood_loss, intra_loss = loss_fn(outputs, label, num_update)\n",
        "        (loss/iter_batch).backward()\n",
        "        train_likelihood += float(likelihood_loss)/iter_batch\n",
        "        train_intra += float(intra_loss)/iter_batch\n",
        "        if (j+1) % iter_batch == 0:\n",
        "            print(loss)\n",
        "            for g in optimizer.param_groups:\n",
        "                if num_update < 50:\n",
        "                    g['lr'] = 0.00002 * num_update\n",
        "                else:\n",
        "                    g['lr'] = 0.001 / np.sqrt(num_update-49)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            num_update += 1\n",
        "\n",
        "    model.eval()\n",
        "    for batch, label in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        label = label.to(device)\n",
        "        output = model(batch)\n",
        "        loss = val_loss_fn(output, label)\n",
        "        val_likelihood += float(loss)\n",
        "\n",
        "    stat = [train_likelihood/50, train_intra/50, val_likelihood/170]\n",
        "    curve.append(stat)\n",
        "\n",
        "    np.savetxt(f'/content/gdrive/My Drive/1.5{mask_type}_curve.txt', np.array(curve))\n",
        "    torch.save(model.state_dict(), f'/content/gdrive/My Drive/1.5{mask_type}_{epoch}.mdl')"
      ],
      "metadata": {
        "id": "3PrWCg7Uygm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_lr = 0.00002\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=0.001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "num_update = 1\n",
        "curve = []\n",
        "optimizer.zero_grad()\n",
        "\n",
        "for epoch in range(80):\n",
        "    train_likelihood = 0\n",
        "    val_likelihood = 0\n",
        "\n",
        "    model.train()\n",
        "    for j, (batch, label) in enumerate(train_loader):\n",
        "        outputs = torch.empty(K, batch_size, num_classes)\n",
        "        batch = batch.to(device)\n",
        "        label = label.to(device)\n",
        "        output = model(batch)\n",
        "        loss = loss_fn(output, label)\n",
        "        (loss/iter_batch).backward()\n",
        "        train_likelihood += float(loss)/iter_batch\n",
        "        if (j+1) % iter_batch == 0:\n",
        "            print(loss)\n",
        "            for g in optimizer.param_groups:\n",
        "                if num_update < 50:\n",
        "                    g['lr'] = 0.00002 * num_update\n",
        "                else:\n",
        "                    g['lr'] = 0.001 / np.sqrt(num_update-49)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            num_update += 1\n",
        "\n",
        "    model.eval()\n",
        "    for batch, label in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        label = label.to(device)\n",
        "        output = model(batch)\n",
        "        loss = val_loss_fn(output, label)\n",
        "        val_likelihood += float(loss)\n",
        "\n",
        "    stat = [train_likelihood/50, val_likelihood/85]\n",
        "    curve.append(stat)\n",
        "\n",
        "    np.savetxt(f'/content/gdrive/My Drive/classic_curve.txt', np.array(curve))\n",
        "    torch.save(model.state_dict(), f'/content/gdrive/My Drive/classic_{epoch}.mdl')"
      ],
      "metadata": {
        "id": "C2Wt0umMyi3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eANgV-JuVnrk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}