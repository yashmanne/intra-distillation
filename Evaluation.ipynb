{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN5Bs1XoPZTtZu1R2kT/kPB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["This file computes test loss and parameter sensitivity for all models."],"metadata":{"id":"EyIbFHbrS6D8"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"Lsk2YfxVShA4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import numpy as np\n","device = torch.device('cuda')"],"metadata":{"id":"UdA1X5bbtYw8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes = 37\n","batch_size = 4\n","iter_batch = 15"],"metadata":{"id":"yMRQFQ9Rq2A3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V1\n","T = weights.transforms()\n","data = torchvision.datasets.OxfordIIITPet('OxfordIIITPet', transform=T, download=True)\n","train, val = torch.utils.data.random_split(data, [3000, 680], generator=torch.Generator().manual_seed(42))\n","train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False) # Here we do not shuffle the train data for consistency across models\n","test = torchvision.datasets.OxfordIIITPet('OxfordIIITPet', transform=T, download=True, split='test')\n","test_loader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=True)"],"metadata":{"id":"qoWe4Elnq5fg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dropout(p):\n","    return nn.Sequential(nn.ReLU(), nn.Dropout(p=p))\n","def set_dropout(model, p):\n","    for name, child in model.named_children():\n","        if isinstance(child, nn.ReLU):\n","            model.relu = dropout(p)\n","        set_dropout(child, p)\n","def make_model(model_name=''):\n","    model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n","    model.fc = torch.nn.Linear(2048, num_classes, bias=False)\n","    set_dropout(model, 0.1)\n","    model = model.to(device)\n","    if model_name != '':\n","        model.load_state_dict(torch.load(f'/content/gdrive/My Drive/{model_name}'))\n","    model.eval();\n","    return model"],"metadata":{"id":"XQx9u7QZsXR6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For each model, select the iteration with lowest validation loss\n","\n","def lowest_val_loss(name):\n","    results = np.loadtxt(f'/content/gdrive/My Drive/{name}_curve.txt')\n","    val_idx = results.shape[-1]-1\n","    return np.argmin(results[:, val_idx])\n","\n","names = ['intranosmooth','intranosmoothr1',\n","         'intrasmooth', 'intrasmoothr1',\n","         'classicnosmooth','classicnosmoothr1',\n","         'classicsmooth', 'classicsmoothr1',]\n","best = [lowest_val_loss(name) for name in names]\n","models = [(name, make_model(f'{name}_{epoch}.mdl')) for name, epoch in zip(names, best)]"],"metadata":{"id":"t5qMUJfL4XWk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses = []\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","for batch, label in test_loader:\n","    batch = batch.to(device)\n","    label = label.to(device)\n","    batch_loss = []\n","    batch_correct = []\n","    for name, model in models:\n","        output = model(batch)\n","        loss = loss_fn(output, label)\n","        batch_loss.append(float(batch.shape[0] * loss))\n","    losses.append(batch_loss)\n","loss = np.array(losses).mean(0)\n","print('test loss:', loss)"],"metadata":{"id":"wnYbj7TxzD0o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_fn = torch.nn.CrossEntropyLoss()\n","n_batches = len(train_loader) / (batch_size*iter_batch)\n","parameters = torch.concat([param.data.flatten() for param in list(models[0][1].parameters())]).detach().to('cpu')\n","n_parameters = len(parameters)\n","\n","for name, model in models:\n","    model.zero_grad()\n","    sensitivity = torch.zeros(n_parameters)\n","    norm_sensitivity = torch.zeros(n_parameters)\n","    cumulative_loss = 0\n","    for i, (batch, label) in enumerate(train_loader):\n","        batch = batch.to(device)\n","        label = label.to(device)\n","        \n","        output = model(batch)\n","        loss = loss_fn(output, label)/iter_batch\n","        loss.backward()\n","        cumulative_loss += float(loss)\n","\n","        if (i+1) % iter_batch == 0:\n","            gradients = torch.concat([param.grad.flatten() for param in list(model.parameters())]).detach().to('cpu')\n","            batch_sensitivity = torch.abs(parameters * gradients)\n","            norm_batch_sensitivity = torch.abs(parameters * gradients / cumulative_loss)\n","            sensitivity += batch_sensitivity\n","            norm_sensitivity += norm_batch_sensitivity\n","    std_sensitivity = torch.std(sensitivity / n_batches)\n","    norm_std_sensitivity = torch.std(norm_sensitivity/ n_batches)\n","    print(f'{name} standard deviation of parameter sensitivity:', float(std_sensitivity))\n","    print(f'{name} normalized standard deviation of parameter sensitivity:', float(norm_std_sensitivity))"],"metadata":{"id":"0QuVIYkqyTZ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c_IpMQosWiLi"},"execution_count":null,"outputs":[]}]}