{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1jo9sBJr85K53TQICbcppimjL-YhEfFzk","timestamp":1678562631143},{"file_id":"1Hh-IoFB9ZH-3tFw673dx3ylByB_9xsDS","timestamp":1678558952795}],"authorship_tag":"ABX9TyPi0x0fL7r24ZorsYcfkPuJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["This file trains the baseline teacher and student models without label smoothing."],"metadata":{"id":"baOzdfA8uHKr"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"95Ea00dGuEuD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import numpy as np\n","device = torch.device('cuda')"],"metadata":{"id":"hIbBDlSKWz-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 4 # Gradients are updated every 60 samples, but we run 4 samples at a time to save memory.\n","iter_batch = 15\n","epochs = 80\n","num_classes = 37\n","kd = 1\n","base_lr = 0.00002\n","weight_decay = 0.001\n","dropout_p = 0.1\n","name = 'classicnosmooth'"],"metadata":{"id":"n4sbu1ukWoKN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V1\n","T = weights.transforms()\n","data = torchvision.datasets.OxfordIIITPet('OxfordIIITPet', transform=T, download=True)\n","train, val = torch.utils.data.random_split(data, [3000, 680], generator=torch.Generator().manual_seed(42))\n","train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"6TvU3ej_xuzL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dropout(p):\n","    return nn.Sequential(nn.ReLU(), nn.Dropout(p=p))\n","def set_dropout(model, p):\n","    for name, child in model.named_children():\n","        if isinstance(child, nn.ReLU):\n","            model.relu = dropout(p)\n","        set_dropout(child, p)\n","def make_model(model_name='', p=dropout_p):\n","    model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n","    model.fc = torch.nn.Linear(2048, num_classes, bias=False)\n","    set_dropout(model, p)\n","    model = model.to(device)\n","    if model_name != '':\n","        model.load_state_dict(torch.load(f'/content/gdrive/My Drive/{model_name}'))\n","    model.eval();\n","    return model"],"metadata":{"id":"T2BBcrGlO8zX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the teacher\n","\n","model = make_model()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=weight_decay)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","num_update = 1\n","curve = []\n","optimizer.zero_grad()\n","\n","for epoch in range(epochs):\n","    train_likelihood = 0\n","    train_intra = 0\n","    val_likelihood = 0\n","\n","    model.train()\n","    for j, (batch, label) in enumerate(train_loader):\n","        batch = batch.to(device)\n","        label = label.to(device)\n","        output = model(batch)\n","        loss = loss_fn(output, label)\n","        (loss/iter_batch).backward()\n","        train_likelihood += float(loss)/iter_batch\n","        if (j+1) % iter_batch == 0:\n","            for g in optimizer.param_groups:\n","                if num_update < 50:\n","                    g['lr'] = base_lr * num_update\n","                else:\n","                    g['lr'] = 0.001 / np.sqrt(num_update-49)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            num_update += 1\n","\n","    model.eval()\n","    for batch, label in val_loader:\n","        batch = batch.to(device)\n","        label = label.to(device)\n","        output = model(batch)\n","        loss = loss_fn(output, label)\n","        val_likelihood += float(loss)\n","\n","    stat = [train_likelihood/50, val_likelihood/170]\n","    curve.append(stat)\n","\n","    np.savetxt(f'/content/gdrive/My Drive/{name}_curve.txt', np.array(curve))\n","    torch.save(model.state_dict(), f'/content/gdrive/My Drive/{name}_{epoch}.mdl')"],"metadata":{"id":"VQT-HfCaxwyU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute the teacher predictions for self-distillation\n","\n","def teacher_loss_fn(outputs, teacher_outputs):\n","    p = torch.softmax(teacher_outputs, dim=-1)\n","    q = torch.softmax(outputs, dim=-1)\n","    return - torch.mean(torch.sum(p * torch.log(q), dim=-1))\n","\n","model = make_model(f'{name}_{epochs-1}.mdl')\n","next_data = []\n","\n","for img, label in train:\n","    output = model(img.to(device)[None,...]).to('cpu').detach()[0]\n","    next_data.append((img, output, label))\n","next_train_dataloader = torch.utils.data.DataLoader(next_data, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"SIYlyKil4W-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the student\n","\n","model = make_model()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=weight_decay)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","num_update = 1\n","curve = []\n","optimizer.zero_grad()\n","\n","for epoch in range(epochs):\n","    train_likelihood = 0\n","    train_teacher = 0\n","    val_likelihood = 0\n","\n","    model.train()\n","    for j, (img, teacher, label) in enumerate(next_train_dataloader):\n","        img = img.to(device)\n","        teacher = teacher.to(device)\n","        label = label.to(device)\n","        output = model(img)\n","        intrinsic_loss = loss_fn(output, label)\n","        teacher_loss = teacher_loss_fn(output, teacher)\n","        train_likelihood += float(intrinsic_loss)/iter_batch\n","        train_teacher += float(teacher_loss)\n","        if epoch >= 75:\n","            loss = intrinsic_loss\n","        else:\n","            loss = intrinsic_loss + kd * teacher_loss\n","        loss.backward()\n","\n","        if (j+1) % iter_batch == 0:\n","            for g in optimizer.param_groups:\n","                if num_update < 50:\n","                    g['lr'] = base_lr * num_update\n","                else:\n","                    g['lr'] = 0.001 / np.sqrt(num_update-49)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            num_update += 1\n","\n","    model.eval()\n","    for batch, label in val_loader:\n","        batch = batch.to(device)\n","        label = label.to(device)\n","        output = model(batch)\n","        loss = loss_fn(output, label)\n","        val_likelihood += float(loss)\n","\n","    stat = [train_likelihood/50, train_teacher/50, val_likelihood/170]\n","    curve.append(stat)\n","\n","    np.savetxt(f'/content/gdrive/My Drive/{name}r1_curve.txt', np.array(curve))\n","    torch.save(model.state_dict(), f'/content/gdrive/My Drive/{name}r1_{epoch}.mdl')"],"metadata":{"id":"W93op0H1xz_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XmvCWTB253c7"},"execution_count":null,"outputs":[]}]}